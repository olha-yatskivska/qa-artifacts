
# ğŸ“‹ Test Plan: OpenWeatherMap API
> **Identifier:** #TP001  
> [cite_start]**Source Document:** [One page Test_Plan.docx] [cite: 1]

---

## ğŸ” Project Overview
| Attribute | Details |
| :--- | :--- |
| **Project** | [cite_start]OpenWeatherMap [cite: 1] |
| **Site** | [cite_start][openweathermap.org](https://openweathermap.org) [cite: 1] |
| **Owner** | [cite_start]Alexander Zhdan [cite: 1] |
| **Release / Sprint** | [cite_start]Release Summer2018 / Sprint Summer2018_1 [cite: 1] |

---

## ğŸ“– Introduction
[cite_start]This plan outlines the basic approaches to testing the **OpenWeatherMap** web application[cite: 1]. [cite_start]Additional project information is available at [openweathermap.org/about](https://openweathermap.org/about)[cite: 1].

## ğŸ¯ Goals
1. [cite_start]**API Testing:** Execute comprehensive testing of the OpenWeatherMap API[cite: 1].
2. [cite_start]**Test Documentation:** Create a Checklist and a Test Report based on the API testing results[cite: 1].

## ğŸ—ï¸ Scope
* [cite_start]**In Scope:** API testing (available at [https://openweathermap.org/api](https://openweathermap.org/api))[cite: 1].
* [cite_start]**Out Of Scope:** Performance, UI, Functional, Security, and Load testing[cite: 1].

## âš ï¸ Risks
* [cite_start]Network Issues[cite: 1].
* [cite_start]Software Issues[cite: 1].
* [cite_start]Time Constraints[cite: 1].
* [cite_start]Challenges with the definition of correct requirements[cite: 1].

## âš™ï¸ Environments & Tools
* [cite_start]**Operating System:** Microsoft Windows 7+[cite: 1].
* [cite_start]**Browsers:** Chrome (latest version), Firefox (latest version)[cite: 1].
* [cite_start]**Source Control (SVC):** GitHub[cite: 1].
* [cite_start]**API Testing Tools:** REST, Postman, Restlet Client, JSON[cite: 1].

## ğŸ Criteria

### Entry Criteria
* [cite_start][ ] Requirements and test goals are clearly defined for testers[cite: 1].
* [cite_start][ ] All test environments and tools are ready for use[cite: 1].
* [cite_start][ ] Test data and documentation are available[cite: 1].
* [cite_start][ ] The Checklist is prepared and ready for execution[cite: 1].

### Exit Criteria
* [cite_start][ ] Allocated test time has concluded[cite: 1].
* [cite_start][ ] At least **85%** of all test scenarios from the Checklist have passed[cite: 1].
* [cite_start][ ] The Test Report is finalized and provided to stakeholders[cite: 1].

## ğŸ‘¥ People
* [cite_start]**QA Engineer:** Zhdan Alexander[cite: 1].

## ğŸ“… Schedule and Estimations
[cite_start]**Project Timeline:** 25.05.18 â€“ 03.06.18 [cite: 1]

| Task | Estimation |
| :--- | :--- |
| Analysis and investigation of the testing scope | [cite_start]2 days [cite: 1] |
| Creation of Test Documentation (Test Plan and Checklist) | [cite_start]2 days [cite: 1] |
| Testing Execution | [cite_start]2 days [cite: 1] |
| Creation of Test Report and full information delivery | [cite_start]1 day [cite: 1] |

---

## ğŸ“š Reference Templates & Standards
* [**RUP Test Plan Template**](https://www.ibm.com/docs/en/rational-soft-arch/9.7.0?topic=artifacts-test-plan) â€” A heavy-weight, formal methodology for large-scale projects.
* **IEEE 829 Standard** â€” The traditional global standard for software test documentation.
* **Agile Test Plan** â€” A streamlined approach (similar to this one-page plan) focused on speed and flexibility.

---

### ğŸ›¡ï¸ Importance for a Test Analyst
As a **Test Analyst**, this document serves several critical functions:
* [cite_start]**Defining Boundaries:** Clearly stating what is "Out of Scope" (e.g., Performance or Security) protects you from "scope creep" and unrealistic expectations[cite: 1].
* [cite_start]**Quantitative Quality (Exit Criteria):** Setting a **85% pass rate** provides a measurable definition of "done," allowing for objective quality assessment instead of subjective guessing[cite: 1].
* [cite_start]**Resource Planning:** By estimating specific days for analysis versus execution, you ensure that the testing phase isn't squeezed at the end of the development cycle[cite: 1].
* [cite_start]**Risk Awareness:** Explicitly identifying risks like "Issues with requirements" allows you to flag potential blockers to stakeholders before they impact the schedule[cite: 1].
